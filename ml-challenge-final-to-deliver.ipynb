{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13330773,"sourceType":"datasetVersion","datasetId":8451844}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ML Programming Challenge\nAuthor: Nicolò Gandini\n\nMail: ngandini@kth.se","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.393518Z","iopub.execute_input":"2025-10-13T12:42:07.394433Z","iopub.status.idle":"2025-10-13T12:42:07.404072Z","shell.execute_reply.started":"2025-10-13T12:42:07.394393Z","shell.execute_reply":"2025-10-13T12:42:07.403064Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ml-challenge-datasets/EvaluateOnMe.csv\n/kaggle/input/ml-challenge-datasets/TrainOnMe_orig.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Imports and boring stuffs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, RandomizedSearchCV, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\nbase_path = '/kaggle/input/ml-challenge-datasets/'\noutput_path = '/kaggle/working/'\ndataset_ev = base_path + 'EvaluateOnMe.csv'\ndataset_tr = base_path + 'TrainOnMe_orig.csv'\n\nprint('Train data: ' + dataset_tr + '\\nEvaluation data: ' + dataset_ev)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.405582Z","iopub.execute_input":"2025-10-13T12:42:07.405924Z","iopub.status.idle":"2025-10-13T12:42:07.428032Z","shell.execute_reply.started":"2025-10-13T12:42:07.405890Z","shell.execute_reply":"2025-10-13T12:42:07.426957Z"}},"outputs":[{"name":"stdout","text":"Train data: /kaggle/input/ml-challenge-datasets/TrainOnMe_orig.csv\nEvaluation data: /kaggle/input/ml-challenge-datasets/EvaluateOnMe.csv\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Load the data","metadata":{}},{"cell_type":"code","source":"print(\"Loading datasets...\")\ntrain_df = pd.read_csv(dataset_tr, encoding=\"utf-8\")\neval_df = pd.read_csv(dataset_ev)\nprint(\"Dataset loaded, Lesssgoooooooo!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.429041Z","iopub.execute_input":"2025-10-13T12:42:07.429400Z","iopub.status.idle":"2025-10-13T12:42:07.489736Z","shell.execute_reply.started":"2025-10-13T12:42:07.429368Z","shell.execute_reply":"2025-10-13T12:42:07.488777Z"}},"outputs":[{"name":"stdout","text":"Loading datasets...\nDataset loaded, Lesssgoooooooo!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"# Data inspection","metadata":{}},{"cell_type":"code","source":"label_col = \"y\"\n\n# basic label cleaning (keep exact characters but remove stray whitespace)\ntrain_df[label_col] = train_df[label_col].astype(str).str.strip()\n\n# quick checks on labels\nprint(\"QUICK DATASET INSPECTION (just for fun)\\n\")\nprint(f\"Training set shape: {train_df.shape}\")\nprint(f\"Evaluation set shape: {eval_df.shape}\")\nprint(f\"\\nLabel distribution:\\n{train_df[label_col].value_counts()}\")\n\nprint(\"Number of unique labels:\", train_df[label_col].nunique())\nprint(\"Missing label cells (NaN or blank):\", train_df[label_col].isna().sum(), train_df[label_col].eq(\"\").sum())\nprint(\"\\nLabel relative frequencies (proportions):\")\nprint(train_df[label_col].value_counts(normalize=True))\nprint(\"\\nMinimum examples in any class:\", train_df[label_col].value_counts().min())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.490795Z","iopub.execute_input":"2025-10-13T12:42:07.491131Z","iopub.status.idle":"2025-10-13T12:42:07.504953Z","shell.execute_reply.started":"2025-10-13T12:42:07.491101Z","shell.execute_reply":"2025-10-13T12:42:07.503837Z"}},"outputs":[{"name":"stdout","text":"QUICK DATASET INSPECTION (just for fun)\n\nTraining set shape: (1000, 14)\nEvaluation set shape: (10000, 13)\n\nLabel distribution:\ny\nAndjorg     409\nAndsuto     334\nJorgsuto    257\nName: count, dtype: int64\nNumber of unique labels: 3\nMissing label cells (NaN or blank): 0 0\n\nLabel relative frequencies (proportions):\ny\nAndjorg     0.409\nAndsuto     0.334\nJorgsuto    0.257\nName: proportion, dtype: float64\n\nMinimum examples in any class: 257\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"# Data pre-processing","metadata":{}},{"cell_type":"code","source":"# Store exact labels\noriginal_labels = train_df[label_col].unique()\nprint(f\"Original labels: {original_labels}\")\n\n# Check for constant columns\nconstant_cols = []\nfor col in train_df.columns:\n    if col != label_col and train_df[col].nunique() == 1:\n        constant_cols.append(col)\n        print(f\"  Dropping constant column '{col}' (value: {train_df[col].iloc[0]})\")\n\nif not constant_cols:\n    print(\"  No constant columns found\")\n\n# Separate features and target\nX = train_df.drop(columns=[label_col] + constant_cols)\ny = train_df[label_col]\nX_eval = eval_df.drop(columns=constant_cols) if constant_cols else eval_df.copy()\n\nprint(f\"\\nFeatures after cleaning: {X.shape[1]}\")\nprint(f\"Feature names: {list(X.columns)}\")\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(f\"Label encoding:\")\nfor idx, label in enumerate(label_encoder.classes_):\n    print(f\"  {label} -> {idx}\")\n\n# Identify feature types\ncategorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()\nnumeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\nprint(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")\nprint(f\"Numeric features ({len(numeric_features)}): {len(numeric_features)} features\")\n\n# Create preprocessor\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numeric_features),\n        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n    ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.507999Z","iopub.execute_input":"2025-10-13T12:42:07.508280Z","iopub.status.idle":"2025-10-13T12:42:07.534586Z","shell.execute_reply.started":"2025-10-13T12:42:07.508229Z","shell.execute_reply":"2025-10-13T12:42:07.533560Z"}},"outputs":[{"name":"stdout","text":"Original labels: ['Jorgsuto' 'Andjorg' 'Andsuto']\n  Dropping constant column 'x12' (value: True)\n\nFeatures after cleaning: 12\nFeature names: ['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x13']\nLabel encoding:\n  Andjorg -> 0\n  Andsuto -> 1\n  Jorgsuto -> 2\n\nCategorical features (1): ['x7']\nNumeric features (11): 11 features\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# Baseline Random Forest Evaluation\nNote: I tried different models, but I will report here the best one I found, that is the Random Forest.\nI tried decision trees and SVM","metadata":{}},{"cell_type":"code","source":"# Create baseline pipeline\nbaseline_rf = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))\n])\n\n# Cross-validation\nk_splits = 5\ncv = StratifiedKFold(n_splits=k_splits, shuffle=True, random_state=42)\nbaseline_scores = cross_val_score(baseline_rf, X, y_encoded, cv=cv, scoring='accuracy', n_jobs=-1)\n\nprint(f\"Baseline Random Forest (n_estimators=200, default params):\")\nprint(f\"  CV scores: {baseline_scores}\")\nprint(f\"  Mean accuracy: {baseline_scores.mean():.4f} (+/- {baseline_scores.std():.4f})\")\nprint(f\"  Range: [{baseline_scores.min():.4f}, {baseline_scores.max():.4f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:07.535779Z","iopub.execute_input":"2025-10-13T12:42:07.536199Z","iopub.status.idle":"2025-10-13T12:42:09.203851Z","shell.execute_reply.started":"2025-10-13T12:42:07.536177Z","shell.execute_reply":"2025-10-13T12:42:09.202993Z"}},"outputs":[{"name":"stdout","text":"Baseline Random Forest (n_estimators=200, default params):\n  CV scores: [0.835 0.845 0.85  0.845 0.82 ]\n  Mean accuracy: 0.8390 (+/- 0.0107)\n  Range: [0.8200, 0.8500]\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Hyperparameter tuning\nLet's see if he does a better job","metadata":{}},{"cell_type":"code","source":"# Create tuning pipeline\ntuning_rf = Pipeline([\n    ('preprocessor', preprocessor),\n    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n])\n\n# Define parameter grid\nparam_grid = {\n    'classifier__n_estimators': [200, 300, 400, 500],\n    'classifier__max_depth': [10, 15, 20, 25, 30, None],\n    'classifier__min_samples_split': [2, 5, 10, 15],\n    'classifier__min_samples_leaf': [1, 2, 4, 6],\n    'classifier__max_features': ['sqrt', 'log2', 0.5, 0.7],\n    'classifier__bootstrap': [True],\n    'classifier__class_weight': [None, 'balanced']\n}\n\nprint(f\"Parameter space:\")\nprint(f\"  n_estimators: {param_grid['classifier__n_estimators']}\")\nprint(f\"  max_depth: {param_grid['classifier__max_depth']}\")\nprint(f\"  min_samples_split: {param_grid['classifier__min_samples_split']}\")\nprint(f\"  min_samples_leaf: {param_grid['classifier__min_samples_leaf']}\")\nprint(f\"  max_features: {param_grid['classifier__max_features']}\")\nprint(f\"  class_weight: {param_grid['classifier__class_weight']}\")\n\n# Randomized search\nn_iteration = 30\nprint(f\"\\nStarting RandomizedSearchCV ({n_iteration} iterations, {k_splits}-fold CV)...\")\n\nrandom_search = RandomizedSearchCV(\n    tuning_rf,\n    param_grid,\n    n_iter=n_iteration,\n    cv=cv,\n    scoring='accuracy',\n    random_state=42,\n    n_jobs=-1,\n    verbose=1\n)\n\nrandom_search.fit(X, y_encoded)\n\nprint(f\"Tuning complete!, Lessssgooooooooo\")\nprint(f\"\\nBest parameters found:\")\nfor param, value in random_search.best_params_.items():\n    print(f\"  {param.replace('classifier__', '')}: {value}\")\n\nprint(f\"\\nBest CV accuracy: {random_search.best_score_:.4f}\")\nprint(f\"Improvement over baseline: {random_search.best_score_ - baseline_scores.mean():+.4f} ({(random_search.best_score_ - baseline_scores.mean())*100:+.2f}%)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:42:09.204886Z","iopub.execute_input":"2025-10-13T12:42:09.205210Z","iopub.status.idle":"2025-10-13T12:43:33.947434Z","shell.execute_reply.started":"2025-10-13T12:42:09.205189Z","shell.execute_reply":"2025-10-13T12:43:33.946315Z"}},"outputs":[{"name":"stdout","text":"Parameter space:\n  n_estimators: [200, 300, 400, 500]\n  max_depth: [10, 15, 20, 25, 30, None]\n  min_samples_split: [2, 5, 10, 15]\n  min_samples_leaf: [1, 2, 4, 6]\n  max_features: ['sqrt', 'log2', 0.5, 0.7]\n  class_weight: [None, 'balanced']\n\nStarting RandomizedSearchCV (30 iterations, 5-fold CV)...\nFitting 5 folds for each of 30 candidates, totalling 150 fits\nTuning complete!, Lessssgooooooooo\n\nBest parameters found:\n  n_estimators: 400\n  min_samples_split: 2\n  min_samples_leaf: 2\n  max_features: 0.7\n  max_depth: 15\n  class_weight: None\n  bootstrap: True\n\nBest CV accuracy: 0.8530\nImprovement over baseline: +0.0140 (+1.40%)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Error analysis","metadata":{}},{"cell_type":"code","source":"# Get best model\nbest_rf = random_search.best_estimator_\n\n# Get cross-validated predictions\nprint(\"Generating cross-validated predictions for error analysis...\")\ny_pred_cv = cross_val_predict(best_rf, X, y_encoded, cv=cv, n_jobs=-1)\n\n# Confusion matrix\ncm = confusion_matrix(y_encoded, y_pred_cv)\ncm_df = pd.DataFrame(cm,\n                     index=label_encoder.classes_,\n                     columns=label_encoder.classes_)\n\nprint(\"\\nConfusion Matrix:\")\nprint(cm_df)\nprint(\"\\n(Rows=True labels, Columns=Predicted labels)\")\n\n# Per-class metrics\nprint(\"\\nPer-Class Performance:\")\nreport = classification_report(y_encoded, y_pred_cv,\n                              target_names=label_encoder.classes_,\n                              digits=4)\nprint(report)\n\n# Calculate per-class accuracy\nprint(\"Per-Class Accuracy:\")\nfor idx, label in enumerate(label_encoder.classes_):\n    class_mask = y_encoded == idx\n    class_acc = (y_pred_cv[class_mask] == idx).sum() / class_mask.sum()\n    class_samples = class_mask.sum()\n    print(f\"  {label}: {class_acc:.4f} ({class_samples} samples)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:43:33.948480Z","iopub.execute_input":"2025-10-13T12:43:33.948757Z","iopub.status.idle":"2025-10-13T12:43:38.662822Z","shell.execute_reply.started":"2025-10-13T12:43:33.948735Z","shell.execute_reply":"2025-10-13T12:43:38.661728Z"}},"outputs":[{"name":"stdout","text":"Generating cross-validated predictions for error analysis...\n\nConfusion Matrix:\n          Andjorg  Andsuto  Jorgsuto\nAndjorg       383        3        23\nAndsuto        11      307        16\nJorgsuto       60       34       163\n\n(Rows=True labels, Columns=Predicted labels)\n\nPer-Class Performance:\n              precision    recall  f1-score   support\n\n     Andjorg     0.8436    0.9364    0.8876       409\n     Andsuto     0.8924    0.9192    0.9056       334\n    Jorgsuto     0.8069    0.6342    0.7102       257\n\n    accuracy                         0.8530      1000\n   macro avg     0.8477    0.8299    0.8345      1000\nweighted avg     0.8505    0.8530    0.8480      1000\n\nPer-Class Accuracy:\n  Andjorg: 0.9364 (409 samples)\n  Andsuto: 0.9192 (334 samples)\n  Jorgsuto: 0.6342 (257 samples)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"# Train the final model on all the data","metadata":{}},{"cell_type":"code","source":"# Train on entire training set\nprint(\"Training final model with best parameters on all training data...\")\nbest_rf.fit(X, y_encoded)\nprint(\"Training complete, lesssgoooo again\")\n\n# Show feature importance (top 10)\nif hasattr(best_rf.named_steps['classifier'], 'feature_importances_'):\n    # Get feature names after preprocessing\n    feature_names = numeric_features.copy()\n    if categorical_features:\n        cat_encoder = best_rf.named_steps['preprocessor'].named_transformers_['cat']\n        if hasattr(cat_encoder, 'get_feature_names_out'):\n            cat_names = cat_encoder.get_feature_names_out(categorical_features)\n            feature_names.extend(cat_names)\n\n    importances = best_rf.named_steps['classifier'].feature_importances_\n\n    # Sort by importance\n    indices = np.argsort(importances)[::-1]\n\n    print(\"\\nTop 10 Most Important Features:\")\n    for i in range(min(10, len(importances))):\n        idx = indices[i]\n        feat_name = feature_names[idx] if idx < len(feature_names) else f\"Feature_{idx}\"\n        print(f\"  {i+1}. {feat_name}: {importances[idx]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:43:38.663919Z","iopub.execute_input":"2025-10-13T12:43:38.664305Z","iopub.status.idle":"2025-10-13T12:43:40.331633Z","shell.execute_reply.started":"2025-10-13T12:43:38.664274Z","shell.execute_reply":"2025-10-13T12:43:40.330390Z"}},"outputs":[{"name":"stdout","text":"Training final model with best parameters on all training data...\nTraining complete, lesssgoooo again\n\nTop 10 Most Important Features:\n  1. x4: 0.4337\n  2. x11: 0.2367\n  3. x10: 0.1197\n  4. x9: 0.0553\n  5. x8: 0.0429\n  6. x6: 0.0255\n  7. x3: 0.0222\n  8. x2: 0.0208\n  9. x13: 0.0136\n  10. x5: 0.0116\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"# Get predictions","metadata":{}},{"cell_type":"code","source":"# Predict on evaluation data\nprint(\"Generating predictions...\")\ny_eval_encoded = best_rf.predict(X_eval)\n\n# Decode back to original labels\ny_eval_pred = label_encoder.inverse_transform(y_eval_encoded)\n\nprint(f\"Generated {len(y_eval_pred)} predictions\")\n\n# Show prediction distribution\nprint(f\"\\nPrediction distribution:\")\nunique, counts = np.unique(y_eval_pred, return_counts=True)\nfor label, count in zip(unique, counts):\n    percentage = count / len(y_eval_pred) * 100\n    print(f\"  {label}: {count} ({percentage:.1f}%)\")\n\n# Compare with training distribution\nprint(f\"\\nTraining distribution (just for comparison):\")\ntrain_unique, train_counts = np.unique(y, return_counts=True)\nfor label, count in zip(train_unique, train_counts):\n    percentage = count / len(y) * 100\n    print(f\"  {label}: {count} ({percentage:.1f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:43:40.332607Z","iopub.execute_input":"2025-10-13T12:43:40.332938Z","iopub.status.idle":"2025-10-13T12:43:40.578571Z","shell.execute_reply.started":"2025-10-13T12:43:40.332902Z","shell.execute_reply":"2025-10-13T12:43:40.577575Z"}},"outputs":[{"name":"stdout","text":"Generating predictions...\nGenerated 10000 predictions\n\nPrediction distribution:\n  Andjorg: 4361 (43.6%)\n  Andsuto: 3347 (33.5%)\n  Jorgsuto: 2292 (22.9%)\n\nTraining distribution (just for comparison):\n  Andjorg: 409 (40.9%)\n  Andsuto: 334 (33.4%)\n  Jorgsuto: 257 (25.7%)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# Output","metadata":{}},{"cell_type":"code","source":"# Create submission dataframe\nsubmission_df = pd.DataFrame({'y': y_eval_pred})\noutput_file = 'predictions.txt'\n\n# Save WITHOUT header and WITHOUT index\nwith open(output_file, 'w') as f:\n    for label in y_eval_pred:\n        f.write(f\"{label}\\n\")\n\n\nprint(\"Predictions saved\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:43:40.579477Z","iopub.execute_input":"2025-10-13T12:43:40.580073Z","iopub.status.idle":"2025-10-13T12:43:40.589639Z","shell.execute_reply.started":"2025-10-13T12:43:40.580049Z","shell.execute_reply":"2025-10-13T12:43:40.588712Z"}},"outputs":[{"name":"stdout","text":"Predictions saved\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"## Double check to verify the format of the output","metadata":{}},{"cell_type":"code","source":"# Verify output format. Yes I am afraid of\nprint(\"\\nVerifying output format:\")\nwith open(output_file, 'r') as f:\n    first_lines = [f.readline().strip() for _ in range(5)]\n    print(\"First 5 lines of output:\")\n    for i, line in enumerate(first_lines, 1):\n        print(f\"  Line {i}: {line}\")\n\n# Check format\nno_header_check = first_lines[0] in original_labels\nlabels_match_check = all(line in original_labels for line in first_lines)\nline_count = sum(1 for _ in open(output_file))\ncorrect_length = line_count == len(y_eval_pred)\n\nprint(\"\\nFormat verification:\")\nprint(f\"  ✓ No header: {'✓ PASS' if no_header_check else '✗ FAIL - CRITICAL ERROR'}\")\nprint(f\"  ✓ Labels match exactly: {'✓ PASS' if labels_match_check else '✗ FAIL - CRITICAL ERROR'}\")\nprint(f\"  ✓ Correct number of predictions ({len(y_eval_pred)}): {'✓ PASS' if correct_length else '✗ FAIL'}\")\n\nif not (no_header_check and labels_match_check and correct_length):\n    print(\"\\n⚠️  WARNING: Format check failed! Review the output before submission.\")\nelse:\n    print(\"\\n✓ All format checks passed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T12:43:40.590445Z","iopub.execute_input":"2025-10-13T12:43:40.590933Z","iopub.status.idle":"2025-10-13T12:43:40.611380Z","shell.execute_reply.started":"2025-10-13T12:43:40.590909Z","shell.execute_reply":"2025-10-13T12:43:40.610462Z"}},"outputs":[{"name":"stdout","text":"\nVerifying output format:\nFirst 5 lines of output:\n  Line 1: Andsuto\n  Line 2: Andjorg\n  Line 3: Jorgsuto\n  Line 4: Andsuto\n  Line 5: Andsuto\n\nFormat verification:\n  ✓ No header: ✓ PASS\n  ✓ Labels match exactly: ✓ PASS\n  ✓ Correct number of predictions (10000): ✓ PASS\n\n✓ All format checks passed!\n","output_type":"stream"}],"execution_count":37}]}